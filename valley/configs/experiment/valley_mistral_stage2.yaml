deepspeed: valley/configs/deepspeed/config_zero2.json
model_name_or_path: /mnt/bn/luoruipu-disk/weight_pretrained/Mistral-7B-Instruct-v0.1/
video_data_path: /mnt/bn/luoruipu-disk/meta_data/finetune_data/Valley-Instruct/Valley_instruct_84k.json
video_folder: /mnt/bn/luoruipu-disk/meta_data/finetune_data/Valley-Instruct/videos
data_path: /mnt/bn/luoruipu-disk/meta_data/finetune_data/LLaVA-Instruct-150K/llava_instruct_150k.json
image_folder: /mnt/bn/luoruipu-disk/meta_data/finetune_data/train2014
pretrain_mm_mlp_adapter: /mnt/bn/luoruipu-disk/checkpoints/valley-mistral-pretrain/mm_projector.bin
# experiment name

project_name: valley-mistral
run_name: stage2
is_fashion_data: True
vision_tower: openai/clip-vit-large-patch14
version: "mistral"
model_class: 'mistral'
only_mask_system: False
mm_vision_select_feature: 'cls_patch'
mm_vision_select_layer: -2
mm_use_im_start_end: False
mm_use_im_patch_token: False
tune_mm_mlp_adapter: False
freeze_backbone: False
group_by_modality_length: True
bf16: True
fp16: False
lora_enable: False
output_dir: /mnt/bn/luoruipu-disk/checkpoints/valley-mistral-7b
num_train_epochs: 3
per_device_train_batch_size: 4
per_device_eval_batch_size: 4
gradient_accumulation_steps: 1
evaluation_strategy: "no"
save_strategy: "no"
lora_save_strategy: "steps"
save_steps: 3000
learning_rate: 2e-5
weight_decay: 0.
warmup_ratio: 0.03
lr_scheduler_type: cosine
logging_steps: 1
tf32: False
model_max_length: 2048
gradient_checkpointing: True
dataloader_num_workers: 4
lazy_preprocess: True
report_to: wandb